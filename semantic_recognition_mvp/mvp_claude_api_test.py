#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MVP2: Claude API è¯­ä¹‰åˆ†æéªŒè¯

ç›®æ ‡: éªŒè¯é€šè¿‡Claude APIè°ƒç”¨è¿›è¡Œæ„å›¾è¯†åˆ«çš„å¯è¡Œæ€§
æŠ€æœ¯æ ˆ: anthropic SDK, Claude Haikuæ¨¡å‹
è¯„ä¼°æŒ‡æ ‡: å‡†ç¡®ç‡ã€å»¶è¿Ÿã€Tokenç”¨é‡ã€æˆæœ¬
"""

import json
import time
import os
import sys
from pathlib import Path
from typing import Dict, List, Tuple

# è®¾ç½®Windowsæ§åˆ¶å°UTF-8ç¼–ç æ”¯æŒ
if sys.platform == 'win32':
    import codecs
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')
    sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'strict')

try:
    import anthropic
except ImportError:
    print("âŒ ç¼ºå°‘ä¾èµ–: anthropic")
    print("è¯·è¿è¡Œ: pip install anthropic")
    sys.exit(1)

# ===== é…ç½® =====
MODEL_NAME = "claude-3-5-haiku-20241022"
# æ”¯æŒä¸¤ç§ç¯å¢ƒå˜é‡åç§°
API_KEY = os.getenv("ANTHROPIC_API_KEY") or os.getenv("ANTHROPIC_AUTH_TOKEN")
TEST_CASES_FILE = Path(__file__).parent / 'test_cases.json'
OUTPUT_FILE = Path(__file__).parent / 'results' / 'mvp_claude_api_results.json'

# Claude Haiku å®šä»· (2024å¹´11æœˆ)
PRICING = {
    'input_per_mtok': 0.80,   # $0.80 per million tokens
    'output_per_mtok': 4.00   # $4.00 per million tokens
}

# ===== æ ¸å¿ƒå‡½æ•° =====
def load_test_cases() -> List[Tuple[str, str]]:
    """åŠ è½½æµ‹è¯•æ•°æ®é›†"""
    if not TEST_CASES_FILE.exists():
        raise FileNotFoundError(f"æµ‹è¯•æ•°æ®é›†ä¸å­˜åœ¨: {TEST_CASES_FILE}")

    with open(TEST_CASES_FILE, 'r', encoding='utf-8') as f:
        data = json.load(f)

    test_cases = []
    for case in data['test_cases']:
        test_cases.append((case['input'], case['expected_intent']))

    return test_cases


def analyze_via_api(client: anthropic.Anthropic, user_input: str, context: Dict = None) -> Dict:
    """
    ä½¿ç”¨ Claude API åˆ†æç”¨æˆ·æ„å›¾

    Args:
        client: Anthropicå®¢æˆ·ç«¯
        user_input: ç”¨æˆ·è¾“å…¥æ–‡æœ¬
        context: ä»»åŠ¡ä¸Šä¸‹æ–‡ä¿¡æ¯

    Returns:
        {
            'intent': è¯†åˆ«çš„æ„å›¾,
            'confidence': ç½®ä¿¡åº¦,
            'reasoning': åˆ¤æ–­ç†ç”±,
            'latency_ms': å»¶è¿Ÿ(æ¯«ç§’),
            'tokens_used': Tokenç”¨é‡,
            'input_tokens': è¾“å…¥Tokenæ•°,
            'output_tokens': è¾“å‡ºTokenæ•°
        }
    """
    if context is None:
        context = {'current_step': 'implementation', 'code_changes': 0}

    prompt = f"""ä½ æ˜¯ä¸€ä¸ªä»»åŠ¡çŠ¶æ€åˆ†æä¸“å®¶ã€‚è¯·åˆ†æç”¨æˆ·çš„åé¦ˆï¼Œåˆ¤æ–­ä»»åŠ¡åº”è¯¥è½¬ç§»åˆ°å“ªä¸ªçŠ¶æ€ã€‚

**å½“å‰ä»»åŠ¡ä¸Šä¸‹æ–‡**:
- å½“å‰é˜¶æ®µ: {context.get('current_step', 'implementation')}
- ä»£ç ä¿®æ”¹æ¬¡æ•°: {context.get('code_changes', 0)}

**ç”¨æˆ·åé¦ˆ**: "{user_input}"

**è¯·åˆ¤æ–­ç”¨æˆ·æ„å›¾ï¼ˆåªè¾“å‡ºJSONï¼Œä¸è¦å…¶ä»–å†…å®¹ï¼‰**:

å¯é€‰æ„å›¾ç±»å‹:
- complete_success: ä»»åŠ¡å®Œå…¨æˆåŠŸï¼Œæ‰€æœ‰é—®é¢˜å·²è§£å†³
- partial_success: éƒ¨åˆ†æˆåŠŸï¼Œè¿˜æœ‰ä¸€äº›é—®é¢˜éœ€è¦ç»§ç»­ä¿®å¤
- failure: ä¿®å¤å¤±è´¥æˆ–å‡ºç°æ–°é—®é¢˜
- planning_required: éœ€è¦é‡æ–°è®¾è®¡æ–¹æ¡ˆæˆ–æ€è·¯

è¾“å‡ºæ ¼å¼:
{{
  "intent": "æ„å›¾ç±»å‹",
  "confidence": 0.0-1.0,
  "reasoning": "ä¸€å¥è¯è¯´æ˜åˆ¤æ–­ç†ç”±"
}}
"""

    start_time = time.time()
    try:
        response = client.messages.create(
            model=MODEL_NAME,
            max_tokens=200,
            messages=[{"role": "user", "content": prompt}]
        )
        latency = time.time() - start_time

        # è§£æå“åº”
        response_text = response.content[0].text.strip()

        # å°è¯•æå–JSONï¼ˆå¯èƒ½åŒ…å«markdownä»£ç å—ï¼‰
        if '```json' in response_text:
            json_start = response_text.find('```json') + 7
            json_end = response_text.find('```', json_start)
            response_text = response_text[json_start:json_end].strip()
        elif '```' in response_text:
            json_start = response_text.find('```') + 3
            json_end = response_text.find('```', json_start)
            response_text = response_text[json_start:json_end].strip()

        result = json.loads(response_text)

        return {
            'intent': result.get('intent', 'error'),
            'confidence': result.get('confidence', 0.0),
            'reasoning': result.get('reasoning', ''),
            'latency_ms': latency * 1000,
            'tokens_used': response.usage.input_tokens + response.usage.output_tokens,
            'input_tokens': response.usage.input_tokens,
            'output_tokens': response.usage.output_tokens,
            'success': True
        }

    except json.JSONDecodeError as e:
        latency = time.time() - start_time
        return {
            'intent': 'error',
            'confidence': 0.0,
            'reasoning': f'JSONè§£æå¤±è´¥: {str(e)}',
            'latency_ms': latency * 1000,
            'tokens_used': 0,
            'input_tokens': 0,
            'output_tokens': 0,
            'success': False,
            'raw_response': response_text if 'response_text' in locals() else ''
        }

    except Exception as e:
        latency = time.time() - start_time
        return {
            'intent': 'error',
            'confidence': 0.0,
            'reasoning': f'APIè°ƒç”¨å¤±è´¥: {str(e)}',
            'latency_ms': latency * 1000,
            'tokens_used': 0,
            'input_tokens': 0,
            'output_tokens': 0,
            'success': False
        }


def evaluate(client: anthropic.Anthropic, test_cases: List[Tuple[str, str]]) -> Dict:
    """
    è¯„ä¼°å‡†ç¡®ç‡ã€å»¶è¿Ÿã€æˆæœ¬

    Returns:
        {
            'accuracy': å‡†ç¡®ç‡,
            'avg_latency_ms': å¹³å‡å»¶è¿Ÿ,
            'avg_tokens': å¹³å‡Tokenç”¨é‡,
            'estimated_cost_per_call': é¢„ä¼°å•æ¬¡æˆæœ¬,
            'results': è¯¦ç»†ç»“æœåˆ—è¡¨
        }
    """
    correct = 0
    total = len(test_cases)
    results = []
    total_latency = 0
    total_input_tokens = 0
    total_output_tokens = 0
    api_errors = 0

    print(f"å¼€å§‹æµ‹è¯• {total} ä¸ªç”¨ä¾‹...")

    for idx, (user_input, expected_intent) in enumerate(test_cases, 1):
        # æ¨¡æ‹ŸçœŸå®ä¸Šä¸‹æ–‡
        context = {
            'current_step': 'implementation',
            'code_changes': 3
        }

        result = analyze_via_api(client, user_input, context)

        is_correct = result['intent'] == expected_intent and result['success']
        if is_correct:
            correct += 1

        if not result['success']:
            api_errors += 1

        total_latency += result['latency_ms']
        total_input_tokens += result['input_tokens']
        total_output_tokens += result['output_tokens']

        results.append({
            'id': idx,
            'input': user_input,
            'expected': expected_intent,
            'predicted': result['intent'],
            'confidence': result['confidence'],
            'reasoning': result['reasoning'],
            'latency_ms': result['latency_ms'],
            'tokens_used': result['tokens_used'],
            'input_tokens': result['input_tokens'],
            'output_tokens': result['output_tokens'],
            'correct': is_correct,
            'success': result['success']
        })

        # è¿›åº¦æ˜¾ç¤º
        if idx % 10 == 0 or idx == total:
            print(f"  è¿›åº¦: {idx}/{total} ({idx/total*100:.0f}%)")

        # å»¶è¿Ÿæ§åˆ¶ï¼ˆé¿å…è§¦å‘é€Ÿç‡é™åˆ¶ï¼‰
        time.sleep(0.1)

    # è®¡ç®—ç»Ÿè®¡æ•°æ®
    successful_calls = total - api_errors
    accuracy = correct / total if total > 0 else 0.0
    avg_latency = total_latency / successful_calls if successful_calls > 0 else 0.0
    avg_input_tokens = total_input_tokens / successful_calls if successful_calls > 0 else 0.0
    avg_output_tokens = total_output_tokens / successful_calls if successful_calls > 0 else 0.0
    avg_total_tokens = avg_input_tokens + avg_output_tokens

    # æˆæœ¬è®¡ç®—
    estimated_cost_per_call = (
        (avg_input_tokens * PRICING['input_per_mtok'] +
         avg_output_tokens * PRICING['output_per_mtok']) / 1_000_000
    )

    return {
        'accuracy': accuracy,
        'avg_latency_ms': avg_latency,
        'avg_input_tokens': avg_input_tokens,
        'avg_output_tokens': avg_output_tokens,
        'avg_total_tokens': avg_total_tokens,
        'estimated_cost_per_call': estimated_cost_per_call,
        'total_input_tokens': total_input_tokens,
        'total_output_tokens': total_output_tokens,
        'total_cost': (total_input_tokens * PRICING['input_per_mtok'] +
                       total_output_tokens * PRICING['output_per_mtok']) / 1_000_000,
        'api_errors': api_errors,
        'results': results
    }


# ===== ä¸»å‡½æ•° =====
def main():
    print("=" * 60)
    print("  MVP2: Claude API è¯­ä¹‰åˆ†æéªŒè¯")
    print("=" * 60)
    print()

    # æ£€æŸ¥APIå¯†é’¥
    if not API_KEY:
        print("âŒ é”™è¯¯: æœªè®¾ç½®ç¯å¢ƒå˜é‡ ANTHROPIC_API_KEY æˆ– ANTHROPIC_AUTH_TOKEN")
        print("\nè¯·æ‰§è¡Œ(äºŒé€‰ä¸€):")
        print('  export ANTHROPIC_API_KEY="your-api-key"       # Linux/Mac')
        print('  export ANTHROPIC_AUTH_TOKEN="your-api-key"    # Linux/Mac (alternative)')
        print('  set ANTHROPIC_API_KEY=your-api-key           # Windows CMD')
        print('  $env:ANTHROPIC_API_KEY="your-api-key"        # Windows PowerShell')
        sys.exit(1)

    # 1. åŠ è½½æµ‹è¯•æ•°æ®
    print("[1/3] åŠ è½½æµ‹è¯•æ•°æ®...")
    test_cases = load_test_cases()
    print(f"âœ… åŠ è½½å®Œæˆ: {len(test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹")

    # 2. åˆå§‹åŒ–å®¢æˆ·ç«¯
    print(f"\n[2/3] åˆå§‹åŒ– Anthropic å®¢æˆ·ç«¯...")
    print(f"      æ¨¡å‹: {MODEL_NAME}")
    client = anthropic.Anthropic(api_key=API_KEY)
    print(f"âœ… å®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ")

    # 3. è¯„ä¼°
    print(f"\n[3/3] è¯„ä¼°å‡†ç¡®ç‡ã€å»¶è¿Ÿã€æˆæœ¬...")
    print(f"      (é¢„è®¡è€—æ—¶: {len(test_cases) * 0.5:.0f}-{len(test_cases) * 1.5:.0f}ç§’)")
    eval_result = evaluate(client, test_cases)

    # ===== è¾“å‡ºç»“æœ =====
    print("\n" + "=" * 60)
    print("  è¯„ä¼°ç»“æœ")
    print("=" * 60)
    print(f"\nğŸ“Š æ€»ä½“æŒ‡æ ‡:")
    print(f"  å‡†ç¡®ç‡: {eval_result['accuracy']:.2%} ({sum(r['correct'] for r in eval_result['results'])}/{len(test_cases)})")
    print(f"  å¹³å‡å»¶è¿Ÿ: {eval_result['avg_latency_ms']:.0f}ms")
    print(f"  å¹³å‡Tokenç”¨é‡: {eval_result['avg_total_tokens']:.1f} (è¾“å…¥:{eval_result['avg_input_tokens']:.1f}, è¾“å‡º:{eval_result['avg_output_tokens']:.1f})")
    print(f"  é¢„ä¼°å•æ¬¡æˆæœ¬: ${eval_result['estimated_cost_per_call']:.6f}")
    print(f"  æœ¬æ¬¡æµ‹è¯•æ€»æˆæœ¬: ${eval_result['total_cost']:.4f}")
    if eval_result['api_errors'] > 0:
        print(f"  âš ï¸  APIé”™è¯¯: {eval_result['api_errors']} æ¬¡")

    # ç»Ÿè®¡å„æ„å›¾çš„å‡†ç¡®ç‡
    intent_stats = {}
    for r in eval_result['results']:
        intent = r['expected']
        if intent not in intent_stats:
            intent_stats[intent] = {'correct': 0, 'total': 0}
        intent_stats[intent]['total'] += 1
        if r['correct']:
            intent_stats[intent]['correct'] += 1

    print(f"\nğŸ“Š å„æ„å›¾å‡†ç¡®ç‡:")
    for intent, stats in intent_stats.items():
        acc = stats['correct'] / stats['total'] if stats['total'] > 0 else 0
        print(f"  {intent:<20} {acc:>6.1%}  ({stats['correct']}/{stats['total']})")

    # æ˜¾ç¤ºé”™è¯¯æ¡ˆä¾‹
    errors = [r for r in eval_result['results'] if not r['correct']]
    if errors:
        print(f"\nâŒ é”™è¯¯æ¡ˆä¾‹ ({len(errors)}ä¸ª):")
        for r in errors[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
            print(f"  [{r['id']}] {r['input']}")
            print(f"      é¢„æœŸ: {r['expected']}, è¯†åˆ«: {r['predicted']}, ç½®ä¿¡åº¦: {r['confidence']:.2f}")
            print(f"      ç†ç”±: {r['reasoning']}")
            print(f"      å»¶è¿Ÿ: {r['latency_ms']:.0f}ms, Tokens: {r['tokens_used']}")
            print()

    # ===== ä¿å­˜ç»“æœ =====
    print("=" * 60)
    print("  ä¿å­˜ç»“æœ")
    print("=" * 60)

    output_data = {
        'meta': {
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
            'model': MODEL_NAME,
            'test_cases_count': len(test_cases),
            'pricing': PRICING
        },
        'performance': {
            'avg_latency_ms': eval_result['avg_latency_ms'],
            'avg_input_tokens': eval_result['avg_input_tokens'],
            'avg_output_tokens': eval_result['avg_output_tokens'],
            'avg_total_tokens': eval_result['avg_total_tokens'],
            'total_input_tokens': eval_result['total_input_tokens'],
            'total_output_tokens': eval_result['total_output_tokens'],
            'api_errors': eval_result['api_errors']
        },
        'cost': {
            'estimated_cost_per_call': eval_result['estimated_cost_per_call'],
            'total_cost': eval_result['total_cost']
        },
        'accuracy': {
            'overall': eval_result['accuracy'],
            'by_intent': {
                intent: stats['correct'] / stats['total'] if stats['total'] > 0 else 0
                for intent, stats in intent_stats.items()
            }
        },
        'results': eval_result['results'],
        'errors': errors
    }

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)

    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)

    print(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {OUTPUT_FILE}")

    # ===== æ€»ç»“ =====
    print("\n" + "=" * 60)
    print("  æ€»ç»“")
    print("=" * 60)
    print(f"âœ… æ€»ä½“å‡†ç¡®ç‡: {eval_result['accuracy']:.2%}")
    print(f"â±ï¸  å¹³å‡å»¶è¿Ÿ: {eval_result['avg_latency_ms']:.0f}ms")
    print(f"ğŸ’° é¢„ä¼°å•æ¬¡æˆæœ¬: ${eval_result['estimated_cost_per_call']:.6f}")
    print(f"ğŸ¯ æˆåŠŸæ ‡å‡†: å‡†ç¡®ç‡>=95%, å»¶è¿Ÿ<=300ms, æˆæœ¬<=$0.002")

    # åˆ¤æ–­æ˜¯å¦è¾¾æ ‡
    meets_accuracy = eval_result['accuracy'] >= 0.95
    meets_latency = eval_result['avg_latency_ms'] <= 300
    meets_cost = eval_result['estimated_cost_per_call'] <= 0.002

    if meets_accuracy and meets_latency and meets_cost:
        print("\nğŸ‰ æ–¹æ¡ˆ3(Claude API)è¾¾åˆ°æ‰€æœ‰æˆåŠŸæ ‡å‡†!")
    else:
        print("\nâš ï¸  æ–¹æ¡ˆ3æœªå®Œå…¨è¾¾æ ‡:")
        if not meets_accuracy:
            print(f"   - å‡†ç¡®ç‡ {eval_result['accuracy']:.2%} < 95%")
        if not meets_latency:
            print(f"   - å»¶è¿Ÿ {eval_result['avg_latency_ms']:.0f}ms > 300ms")
        if not meets_cost:
            print(f"   - æˆæœ¬ ${eval_result['estimated_cost_per_call']:.6f} > $0.002")

    print("=" * 60)


if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\n\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
