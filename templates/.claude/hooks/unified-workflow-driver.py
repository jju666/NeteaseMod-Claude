#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Unified Workflow Driver - ç»Ÿä¸€å·¥ä½œæµé©±åŠ¨å™¨ (v20.0.3)

è§¦å‘æ—¶æœº: PostToolUse (Read/Write/Edit/Bash)
èŒè´£:
1. å¿«é€Ÿæ£€æŸ¥ .task-active.json,æ— æ´»è·ƒä»»åŠ¡åˆ™è·³è¿‡
2. æ ¹æ®å·¥å…·ç±»å‹åˆ†å‘å¤„ç†
3. æ›´æ–°ä»»åŠ¡çŠ¶æ€æœº
4. æ£€æŸ¥æ­¥éª¤å®Œæˆæ¡ä»¶
5. æ³¨å…¥ä¸‹ä¸€æ­¥æŒ‡ä»¤(é˜²é‡å¤æ³¨å…¥)

é€€å‡ºç :
- 0: æˆåŠŸ
"""

import sys
import json
import os
from datetime import datetime
import io

# Windowsç¼–ç ä¿®å¤
if sys.platform == 'win32':
    sys.stdin = io.TextIOWrapper(sys.stdin.buffer, encoding='utf-8')
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# Import logger
try:
    from hook_logger import HookLogger
except ImportError:
    class HookLogger:
        def __init__(self, name): self.name = name
        def start(self): pass
        def finish(self, success=True, message=""): pass
        def info(self, msg, data=None): pass
        def error(self, msg, err=None): pass
        def decision(self, t, r, d=None): pass

# Import notification module (v20.1)
try:
    from vscode_notify import notify_info
except ImportError:
    def notify_info(msg, detail=""): pass

def load_json(file_path):
    """åŠ è½½JSONæ–‡ä»¶"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except:
        return None

def save_json(file_path, data):
    """ä¿å­˜JSONæ–‡ä»¶"""
    try:
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        return True
    except:
        return False

def update_docs_read(meta, file_path):
    """æ›´æ–°æ–‡æ¡£é˜…è¯»è®°å½•"""
    if not file_path.endswith('.md'):
        return False

    # æ’é™¤ä¸è®¡å…¥çš„æ–‡æ¡£
    excluded = ['README.md', 'CHANGELOG.md', u'ç´¢å¼•.md', u'é¡¹ç›®çŠ¶æ€.md', u'æ–‡æ¡£å¾…è¡¥å……æ¸…å•.md']
    if any(pattern in file_path for pattern in excluded):
        return False

    docs_read = meta.get("metrics", {}).get("docs_read", [])
    if file_path not in docs_read:
        docs_read.append(file_path)
        meta["metrics"]["docs_read"] = docs_read
        meta["metrics"]["docs_read_count"] = len(docs_read)

        # åŒæ­¥åˆ°step2_docs
        if "step2_docs" in meta["workflow_state"]["steps"]:
            meta["workflow_state"]["steps"]["step2_docs"]["docs_read"] = docs_read

        return True
    return False

def update_code_changes(meta, tool_data):
    """è®°å½•ä»£ç ä¿®æ”¹"""
    file_path = tool_data.get("tool_input", {}).get("file_path", "")
    if not file_path:
        return False

    change_record = {
        "file": file_path,
        "timestamp": datetime.now().isoformat(),
        "operation": tool_data.get("tool_name", "Unknown")
    }

    if "code_changes" not in meta["metrics"]:
        meta["metrics"]["code_changes"] = []

    meta["metrics"]["code_changes"].append(change_record)
    meta["metrics"]["code_changes_count"] = len(meta["metrics"]["code_changes"])
    return True

def check_test_failure(result_str):
    """æ£€æµ‹æµ‹è¯•å¤±è´¥"""
    failure_indicators = [
        'error', 'Error', 'ERROR',
        'failed', 'Failed', 'FAILED',
        'traceback', 'Traceback',
        'exception', 'Exception'
    ]
    return any(indicator in result_str for indicator in failure_indicators)

# ==================== v20.2 æ–°å¢ï¼šå¾ªç¯æ£€æµ‹ä¸ä¸“å®¶è§¦å‘ ====================

def check_expert_trigger(meta, cwd):
    """
    å¾ªç¯æ£€æµ‹å™¨ - åˆ¤æ–­æ˜¯å¦è§¦å‘ä¸“å®¶å®¡æŸ¥

    è¿”å›:
    {
        "should_trigger": bool,
        "loop_type": "bug_fix_loop" | "requirement_mismatch" | None,
        "confidence": float,
        "evidence": dict
    }
    """

    # è¯»å–workflow-stateä»¥è·å–tracking_state
    workflow_state_path = os.path.join(cwd, '.claude', 'workflow-state.json')
    workflow_state = load_json(workflow_state_path)

    if not workflow_state:
        return {"should_trigger": False, "loop_type": None}

    # === Bugä¿®å¤å¾ªç¯æ£€æµ‹ ===
    if workflow_state.get("bug_fix_tracking", {}).get("enabled"):
        tracking = workflow_state["bug_fix_tracking"]
        indicators = tracking.get("loop_indicators", {})
        iterations_count = len(tracking.get("iterations", []))

        # è§¦å‘æ¡ä»¶:
        # 1. è‡³å°‘2æ¬¡è¿­ä»£
        # 2. è‡³å°‘2æ¬¡è´Ÿé¢åé¦ˆ
        # 3. è‡³å°‘2æ¬¡åŒæ–‡ä»¶ä¿®æ”¹
        negative_count = indicators.get("negative_feedback_count", 0)
        same_file_count = indicators.get("same_file_edit_count", 0)

        if (iterations_count >= 2 and
            negative_count >= 2 and
            same_file_count >= 2):

            return {
                "should_trigger": True,
                "loop_type": "bug_fix_loop",
                "confidence": 0.9,
                "evidence": {
                    "iterations": iterations_count,
                    "negative_feedback": negative_count,
                    "same_file_edits": same_file_count,
                    "pattern": u"è¡¨è±¡ä¿®å¤å¾ªç¯ - åå¤ä¿®æ”¹åŒä¸€ä½ç½®ä½†æœªè§£å†³æ ¹æœ¬é—®é¢˜"
                }
            }

    # === éœ€æ±‚å®ç°å¾ªç¯æ£€æµ‹ ===
    if workflow_state.get("feature_tracking", {}).get("enabled"):
        tracking = workflow_state["feature_tracking"]
        iterations_count = len(tracking.get("iterations", []))
        requirement_changes = len(tracking.get("requirement_changes", []))

        # è§¦å‘æ¡ä»¶:
        # 1. è‡³å°‘2æ¬¡è¿­ä»£
        # 2. è‡³å°‘2æ¬¡ä¸æ»¡æ„åé¦ˆ
        dissatisfied_count = sum(
            1 for iter in tracking.get("iterations", [])
            if iter.get("user_satisfaction") == "dissatisfied"
        )

        if (iterations_count >= 2 and dissatisfied_count >= 2):

            return {
                "should_trigger": True,
                "loop_type": "requirement_mismatch",
                "confidence": 0.85,
                "evidence": {
                    "iterations": iterations_count,
                    "dissatisfied_count": dissatisfied_count,
                    "requirement_changes": requirement_changes,
                    "pattern": u"éœ€æ±‚ç†è§£åå·® - å®ç°æ–¹å‘ä¸ç”¨æˆ·æœŸæœ›ä¸ä¸€è‡´"
                }
            }

    return {
        "should_trigger": False,
        "loop_type": None,
        "confidence": 0.0,
        "evidence": {}
    }


def launch_meta_expert(expert_check, meta, cwd, logger):
    """
    å¯åŠ¨Meta-Expertä¸“å®¶åˆ†æ

    æµç¨‹:
    1. è¯»å–å®Œæ•´çš„è¿­ä»£å†å²
    2. æ„å»ºä¸“å®¶åˆ†æprompt
    3. æ³¨å…¥åˆ°å¯¹è¯ä¸Šä¸‹æ–‡
    4. ç­‰å¾…AIç”Ÿæˆåˆ†ææŠ¥å‘Š
    """

    loop_type = expert_check["loop_type"]
    evidence = expert_check["evidence"]

    # è¯»å–workflow-stateè·å–å®Œæ•´å†å²
    workflow_state_path = os.path.join(cwd, '.claude', 'workflow-state.json')
    workflow_state = load_json(workflow_state_path)

    if not workflow_state:
        logger.error(u"æ— æ³•è¯»å–workflow-state")
        return None

    # æ„å»ºå†å²æ‘˜è¦
    history_summary = ""

    if loop_type == "bug_fix_loop":
        tracking = workflow_state.get("bug_fix_tracking", {})
        history_summary = u"## è¿­ä»£å†å²\n\n"

        for iter in tracking.get("iterations", []):
            history_summary += u"### è¿­ä»£ {}\n".format(iter["iteration_id"])
            history_summary += u"- æ—¶é—´: {}\n".format(iter["timestamp"])
            history_summary += u"- ç”¨æˆ·åé¦ˆ: {}\n".format(iter.get("user_feedback", "æ— "))
            history_summary += u"- æƒ…æ„Ÿ: {}\n".format(iter.get("feedback_sentiment", "neutral"))
            history_summary += u"- ä¿®æ”¹æ–‡ä»¶:\n"
            for change in iter.get("changes_made", []):
                history_summary += u"  - {}: {}\n".format(change["file"], change["change_summary"])
            history_summary += u"\n"

    elif loop_type == "requirement_mismatch":
        tracking = workflow_state.get("feature_tracking", {})
        history_summary = u"## éœ€æ±‚è°ƒæ•´å†å²\n\n"

        for iter in tracking.get("iterations", []):
            history_summary += u"### è¿­ä»£ {}\n".format(iter["iteration_id"])
            history_summary += u"- æ—¶é—´: {}\n".format(iter["timestamp"])
            history_summary += u"- ç”¨æˆ·æ»¡æ„åº¦: {}\n".format(iter.get("user_satisfaction", "neutral"))
            history_summary += u"- è°ƒæ•´è¯·æ±‚: {}\n\n".format(iter.get("adjustment_request", "æ— "))

    # æ„å»ºä¸“å®¶åˆ†æprompt
    expert_prompt = u"""
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ¯ ä¸“å®¶å®¡æŸ¥ç³»ç»Ÿå·²è§¦å‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## æ£€æµ‹åˆ°çš„é—®é¢˜æ¨¡å¼

**å¾ªç¯ç±»å‹**: {}
**ç½®ä¿¡åº¦**: {:.0%}
**è¯æ®**:
{}

{}

## ä½ çš„ä»»åŠ¡

ä½ ç°åœ¨éœ€è¦ä»**æˆ˜ç•¥é«˜åº¦**åˆ†æé—®é¢˜ï¼Œè€Œéç»§ç»­å°è¯•ä¿®å¤ã€‚

### åœºæ™¯A: Bugä¿®å¤å¾ªç¯
å¦‚æœæ˜¯Bugä¿®å¤å¾ªç¯ï¼Œè¯·å›ç­”ï¼š

1. **æ ¹å› åˆ†æ**: ä¸ºä»€ä¹ˆåå¤ä¿®æ”¹ä»å¤±è´¥?
   - æ˜¯å¦é™·å…¥è¡¨è±¡ä¿®å¤?
   - æ˜¯å¦å­˜åœ¨æ¶æ„å±‚é¢çš„ç¼ºé™·?
   - æ˜¯å¦å¯¹é—®é¢˜çš„ç†è§£æœ‰è¯¯?

2. **å¤±è´¥æ¨¡å¼**: å†å²ä¿®æ”¹ä¸­æœ‰å“ªäº›å…±åŒçš„é”™è¯¯å‡è®¾?

3. **å¤‡é€‰è·¯å¾„**: é™¤äº†å½“å‰æ–¹å‘ï¼Œè¿˜æœ‰å“ª3-5ç§å¯èƒ½çš„è§£å†³æ€è·¯?
   - è·¯å¾„A: [åç§°] - [ä¼˜ç‚¹] - [ç¼ºç‚¹] - [é€‚ç”¨åœºæ™¯]
   - è·¯å¾„B: ...

4. **æ¨èç­–ç•¥**: æ¨èå“ªç§è·¯å¾„ï¼Œä»¥åŠå¦‚ä½•éªŒè¯?

### åœºæ™¯B: éœ€æ±‚ç†è§£åå·®
å¦‚æœæ˜¯éœ€æ±‚è°ƒæ•´å¾ªç¯ï¼Œè¯·å›ç­”ï¼š

1. **éœ€æ±‚åˆ†æ**: ç”¨æˆ·çœŸæ­£æƒ³è¦ä»€ä¹ˆ?(å¯èƒ½ä¸è¡¨é¢éœ€æ±‚ä¸åŒ)

2. **å·®è·è¯Šæ–­**: å½“å‰å®ç°ä¸ç”¨æˆ·æœŸæœ›çš„æœ¬è´¨å·®è·åœ¨å“ª?

3. **æ–¹æ¡ˆå¯¹æ¯”**: æä¾›3-5ç§å®ç°ç­–ç•¥ï¼Œæ ‡æ³¨ä¼˜ç¼ºç‚¹
   - æ–¹æ¡ˆA: [åç§°] - [ä¼˜ç‚¹] - [ç¼ºç‚¹] - [é¢„è®¡å·¥ä½œé‡]
   - æ–¹æ¡ˆB: ...

4. **æ¾„æ¸…é—®é¢˜**: åˆ—å‡ºéœ€è¦å‘ç”¨æˆ·ç¡®è®¤çš„5ä¸ªå…³é”®é—®é¢˜

## è¾“å‡ºæ ¼å¼

ä½¿ç”¨ä»¥ä¸‹Markdownæ ¼å¼è¾“å‡ºï¼š

# ğŸ¯ ä¸“å®¶è¯Šæ–­æŠ¥å‘Š

## 1. é—®é¢˜æ ¹å› 

[æ·±åº¦åˆ†æ...]

## 2. å¤‡é€‰æ–¹æ¡ˆ

### æ–¹æ¡ˆA: [åç§°]
- **ä¼˜ç‚¹**: ...
- **ç¼ºç‚¹**: ...
- **é€‚ç”¨åœºæ™¯**: ...
- **é¢„è®¡å·¥ä½œé‡**: ...

### æ–¹æ¡ˆB: [åç§°]
...

## 3. æ¨èç­–ç•¥

[å…·ä½“å»ºè®®ï¼ŒåŒ…æ‹¬å®æ–½æ­¥éª¤å’ŒéªŒè¯æ–¹æ³•]

## 4. éœ€è¦å‘ç”¨æˆ·æ¾„æ¸…çš„é—®é¢˜

1. [é—®é¢˜1]
2. [é—®é¢˜2]
...

## é‡è¦æé†’

- âŒ ä¸è¦ç›´æ¥ä¿®æ”¹ä»£ç 
- âŒ ä¸è¦å‡è®¾é—®é¢˜å·²è¢«å‡†ç¡®å®šä½
- âœ… ä»é«˜ç»´åº¦åˆ†æé—®é¢˜æœ¬è´¨
- âœ… æä¾›å¤šç§å¤‡é€‰æ–¹æ¡ˆ
- âœ… æ˜ç¡®æŒ‡å‡ºéœ€è¦æ¾„æ¸…çš„ç‚¹

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

è¯·ç«‹å³å¼€å§‹åˆ†æã€‚
""".format(
        loop_type,
        expert_check["confidence"],
        u"\n".join([u"- {}: {}".format(k, v) for k, v in evidence.items()]),
        history_summary
    )

    # æ ‡è®°ä¸“å®¶å·²è§¦å‘
    meta["metrics"]["expert_review_triggered"] = True
    meta["metrics"]["expert_triggered_at"] = datetime.now().isoformat()

    # ä¿å­˜åˆ°.task-meta.json
    task_dir = meta.get("task_id")
    if task_dir:
        meta_path = os.path.join(cwd, 'tasks', task_dir, '.task-meta.json')
        save_json(meta_path, meta)

    logger.info(u"ä¸“å®¶å®¡æŸ¥å·²è§¦å‘", {
        "loop_type": loop_type,
        "confidence": expert_check["confidence"]
    })

    return expert_prompt

# ==================== v20.2 ç»“æŸ ====================

def check_step_completed(step_name, meta):
    """Check if workflow step is completed (v20.1: removed step2)"""
    steps = meta["workflow_state"]["steps"]

    if step_name == "step0_context":
        docs_read = meta.get("metrics", {}).get("docs_read", [])
        return any("CLAUDE.md" in doc.upper() for doc in docs_read)

    elif step_name == "step1_understand":
        return meta.get("metrics", {}).get("docs_read_count", 0) > 0

    elif step_name == "step3_execute":
        return steps["step3_execute"].get("user_confirmed", False)

    elif step_name == "step4_cleanup":
        return steps["step4_cleanup"]["status"] == "completed"

    return False

def get_next_step(current_step):
    """Get next step in workflow (v20.1: removed step2)"""
    step_order = ["step0_context", "step1_understand", "step3_execute", "step4_cleanup"]
    try:
        current_idx = step_order.index(current_step)
        if current_idx < len(step_order) - 1:
            return step_order[current_idx + 1]
    except ValueError:
        pass
    return None

def trigger_doc_update_agent(meta, cwd):
    """è§¦å‘æ–‡æ¡£æ›´æ–°å­ä»£ç† (v20.0.4)"""
    import subprocess

    logger = HookLogger("doc-update-agent-trigger")
    logger.start()

    try:
        # æ„å»ºå­ä»£ç†ä»»åŠ¡æè¿°
        task_desc = meta.get("task_description", "Unknown Task")
        docs_read = meta.get("metrics", {}).get("docs_read", [])
        code_changes = meta.get("metrics", {}).get("code_changes", [])

        agent_prompt = u"""
ğŸ¤– å­ä»£ç†ä»»åŠ¡ï¼šè‡ªåŠ¨æ–‡æ¡£æ›´æ–°ä¸æ”¶å°¾å·¥ä½œ

**ä»»åŠ¡ä¸Šä¸‹æ–‡**:
- ä¸»ä»»åŠ¡: {}
- å·²é˜…è¯»æ–‡æ¡£: {}ä¸ª
- ä»£ç ä¿®æ”¹: {}å¤„

**ä½ çš„èŒè´£**:
1. æœç´¢ markdown/ ç›®å½•ä¸‹æ‰€æœ‰åŒ…å«"å¾…è¡¥å……"æˆ–"TODO"æ ‡è®°çš„æ–‡æ¡£
2. åˆ†ææ ‡è®°çš„ä¸Šä¸‹æ–‡ï¼Œåˆ¤æ–­æ˜¯å¦ä¸æœ¬æ¬¡ä»»åŠ¡ç›¸å…³
3. å¦‚æœç›¸å…³æ–‡æ¡£â‰¤2ä¸ªï¼Œä½¿ç”¨Editå·¥å…·æ›´æ–°è¿™äº›æ–‡æ¡£çš„å†…å®¹
4. å¦‚æœç›¸å…³æ–‡æ¡£>2ä¸ªï¼Œå°†åˆ—è¡¨è¿½åŠ åˆ° markdown/æ–‡æ¡£å¾…è¡¥å……æ¸…å•.md
5. æœç´¢ä»£ç ä¸­çš„DEBUG/ä¸´æ—¶è°ƒè¯•è¯­å¥ï¼Œå»ºè®®æ¸…ç†
6. è¾“å‡ºæ”¶å°¾æŠ¥å‘Š

**æ‰§è¡Œæ­¥éª¤**:

Step 1: æœç´¢å¾…è¡¥å……æ ‡è®°
```bash
# ä½¿ç”¨Grepæœç´¢markdownç›®å½•
Grep("å¾…è¡¥å……|TODO", path="markdown/", output_mode="files_with_matches", -i=True)
```

Step 2: åˆ†æç›¸å…³æ€§
- é˜…è¯»æœç´¢åˆ°çš„æ–‡æ¡£ç‰‡æ®µï¼ˆä½¿ç”¨Grep -C 3è·å–ä¸Šä¸‹æ–‡ï¼‰
- åˆ¤æ–­æ˜¯å¦ä¸ä¸»ä»»åŠ¡"{}"ç›¸å…³

Step 3: æ‰§è¡Œæ›´æ–°
- å¦‚æœâ‰¤2ä¸ªç›¸å…³æ–‡æ¡£ï¼š
  - ä½¿ç”¨Readè¯»å–å®Œæ•´æ–‡æ¡£
  - æ ¹æ®ä»»åŠ¡å†…å®¹è¡¥å……"å¾…è¡¥å……"éƒ¨åˆ†
  - ä½¿ç”¨Editæ›´æ–°æ–‡æ¡£
- å¦‚æœ>2ä¸ªç›¸å…³æ–‡æ¡£ï¼š
  - ç”Ÿæˆå¾…è¡¥å……æ¸…å•
  - è¿½åŠ åˆ° markdown/æ–‡æ¡£å¾…è¡¥å……æ¸…å•.md

Step 4: DEBUG clean check
```bash
Grep("DEBUG|print.*debug|console.log.*test", path=".", glob="*.py", output_mode="content", -n=True)
```

Step 5: Mark step4 completed (CRITICAL - triggers archive)
Use Write tool to update task metadata:
1. Read latest task's .task-meta.json
2. Set workflow_state.steps.step4_cleanup.status = "completed"
3. Write back the updated JSON

Step 6: Output completion report
Format:
```
==============================================
Cleanup Work Completion Report
==============================================

Docs updated: [file list]
DEBUG cleanup: [count] found, [locations]
Task archive: tasks/task-XXX/
  - context.md: OK
  - solution.md: OK
Step4 marked: COMPLETED (archive hook will trigger)
==============================================
```

**IMPORTANT**:
- You are an independent subagent with full tool access
- Do NOT ask user, complete all steps autonomously
- MUST execute Step 5 to mark step4_cleanup completed
- After marking, post-archive-hook will auto-move task directory
- Keep output concise, focus on execution
""".format(
            task_desc,
            len(docs_read),
            len(code_changes),
            task_desc
        )

        # å†™å…¥ä¸´æ—¶ä»»åŠ¡æ–‡ä»¶
        agent_task_file = os.path.join(cwd, '.claude', '.agent-doc-update.txt')
        with open(agent_task_file, 'w', encoding='utf-8') as f:
            f.write(agent_prompt)

        logger.info(u"å­ä»£ç†ä»»åŠ¡æ–‡ä»¶å·²åˆ›å»º", {"file": agent_task_file})

        # æ³¨å…¥å­ä»£ç†è°ƒç”¨æŒ‡ä»¤
        message = u"""
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ¤– å¯åŠ¨æ–‡æ¡£æ›´æ–°å­ä»£ç†
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

æ£€æµ‹åˆ°æ­¥éª¤4ï¼ˆæ”¶å°¾å½’æ¡£ï¼‰å¼€å§‹ï¼Œç³»ç»Ÿå°†å¯åŠ¨ä¸“é—¨çš„å­ä»£ç†å®Œæˆä»¥ä¸‹å·¥ä½œï¼š
- ğŸ“ è‡ªåŠ¨æ›´æ–°markdownæ–‡æ¡£ä¸­çš„"å¾…è¡¥å……"å†…å®¹
- ğŸ§¹ æ£€æŸ¥å¹¶æ¸…ç†DEBUGä»£ç 
- ğŸ“¦ æ•´ç†ä»»åŠ¡å½’æ¡£

**è¯·ä½¿ç”¨Taskå·¥å…·å¯åŠ¨å­ä»£ç†**ï¼š

```
Task(
    subagent_type="general-purpose",
    description="æ–‡æ¡£æ›´æ–°ä¸æ”¶å°¾å·¥ä½œ",
    prompt=Read("{}").content
)
```

å­ä»£ç†å°†ç‹¬ç«‹å®Œæˆæ‰€æœ‰æ”¶å°¾å·¥ä½œï¼Œä¸æ¶ˆè€—ä¸»ä¼šè¯ä¸Šä¸‹æ–‡ã€‚
å®Œæˆåä¼šè¾“å‡ºè¯¦ç»†æŠ¥å‘Šã€‚

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
""".format(agent_task_file)

        logger.finish(success=True, message=u"å­ä»£ç†è§¦å‘æŒ‡ä»¤å·²æ³¨å…¥")
        return message

    except Exception as e:
        logger.error(u"å­ä»£ç†è§¦å‘å¤±è´¥", e)
        import traceback
        traceback.print_exc(file=sys.stderr)
        return None

def inject_next_step_prompt(next_step, meta, cwd=None):
    """æ³¨å…¥ä¸‹ä¸€æ­¥æŒ‡ä»¤"""
    step_config = meta["workflow_state"]["steps"][next_step]

    # ç‰¹æ®Šå¤„ç†ï¼šæ­¥éª¤4å¯åŠ¨å­ä»£ç†
    if next_step == "step4_cleanup" and cwd:
        agent_message = trigger_doc_update_agent(meta, cwd)
        if agent_message:
            output = {
                "continue": True,
                "hookSpecificOutput": {
                    "hookEventName": "PostToolUse",
                    "additionalContext": agent_message
                }
            }
            print(json.dumps(output, ensure_ascii=False))
            return

    # å¸¸è§„æ­¥éª¤ï¼šæ³¨å…¥æç¤º
    message = u"""
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ¯ å·¥ä½œæµæé†’: {}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

{}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
""".format(step_config.get("description", next_step), step_config["prompt"])

    output = {
        "continue": True,
        "hookSpecificOutput": {
            "hookEventName": "PostToolUse",
            "additionalContext": message
        }
    }

    print(json.dumps(output, ensure_ascii=False))

def detect_failure_pattern(meta):
    """Detect failure patterns (v20.1)"""
    failures = meta["metrics"].get("failures", [])

    if len(failures) < 2:
        return "single_failure"

    recent_failures = failures[-3:]
    error_messages = [f.get("error", "")[:100] for f in recent_failures]

    if len(set(error_messages)) == 1:
        return "repeated_same_error"

    return "varied_errors"

def should_trigger_expert_diagnosis(meta):
    """Check if expert diagnosis should be triggered (v20.1)"""

    if meta["metrics"]["expert_review_triggered"]:
        return False, None

    task_type = meta.get("task_type", "feature")
    complexity = meta.get("task_complexity", "standard")
    failure_count = meta["metrics"]["failure_count"]
    failure_pattern = detect_failure_pattern(meta)

    if failure_pattern == "repeated_same_error" and failure_count >= 3:
        return True, "Repeated same error 3 times"

    if task_type in ["feature", "bugfix"] and failure_count >= 5:
        return True, "Task failed {} times".format(failure_count)

    if task_type == "feature":
        critical_count = meta["metrics"].get("critical_violation_count", 0)
        if critical_count >= 4:
            return True, "CRITICAL violations {} times, may misunderstand rules".format(critical_count)

    if task_type == "bugfix" and failure_count >= 3:
        return True, "Bugfix failed 3 times, may be mislocated"

    if complexity == "complex":
        time_in_step3 = meta["workflow_state"]["steps"]["step3_execute"].get("elapsed_minutes", 0)
        if time_in_step3 >= 30 and failure_count >= 2:
            return True, "Complex task taking too long with difficulties"

    return False, None

def inject_expert_review_warning(meta, trigger_reason=None):
    """Inject expert review warning (v20.1: enhanced)"""
    task_desc = meta["task_description"]
    failure_count = meta["metrics"]["failure_count"]
    last_error = meta["workflow_state"]["steps"]["step3_execute"].get("last_error", u"Unknown error")
    reason = trigger_reason if trigger_reason else "Multiple failures detected"

    sys.stderr.write(u"""
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âš ï¸  Warning: Task encountering difficulties, expert review recommended
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**Task**: {}
**Failure Count**: {} times
**Trigger Reason**: {}
**Recent Error**: {}

**Expert Review Process**:
1. System will inject detailed debugging context
2. AI will re-analyze root cause
3. Provide deeper solution

**Continue current approach?**
- Input "trigger expert review" â†’ Start deep analysis
- Input "continue trying" â†’ Keep current approach

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
""".format(task_desc, failure_count, reason, last_error))

def main():
    logger = HookLogger("unified-workflow-driver")
    logger.start()

    try:
        # è¯»å–stdinè¾“å…¥
        data = json.load(sys.stdin)
        tool_name = data.get('tool_name', '')
        cwd = os.environ.get('CLAUDE_PROJECT_DIR', os.getcwd())

        # å¿«é€Ÿæ£€æŸ¥: æ˜¯å¦æœ‰æ´»è·ƒä»»åŠ¡
        active_flag_path = os.path.join(cwd, '.claude', '.task-active.json')
        if not os.path.exists(active_flag_path):
            logger.decision("skip", u"æ— æ´»è·ƒä»»åŠ¡,è·³è¿‡")
            output = {"continue": True}
            print(json.dumps(output, ensure_ascii=False))
            logger.finish(success=True, message=u"è·³è¿‡")
            sys.exit(0)

        # åŠ è½½æ´»è·ƒä»»åŠ¡
        active_flag = load_json(active_flag_path)
        if not active_flag:
            logger.error(u"æ´»è·ƒä»»åŠ¡æ ‡å¿—æŸå")
            output = {"continue": True}
            print(json.dumps(output, ensure_ascii=False))
            sys.exit(0)

        task_dir = active_flag["task_dir"]
        meta_path = os.path.join(task_dir, '.task-meta.json')
        meta = load_json(meta_path)

        if not meta:
            logger.error(u"ä»»åŠ¡å…ƒæ•°æ®æŸå")
            output = {"continue": True}
            print(json.dumps(output, ensure_ascii=False))
            sys.exit(0)

        current_step = meta["workflow_state"]["current_step"]
        last_injection = meta["workflow_state"].get("last_injection_step", None)

        logger.info(u"å¤„ç†å·¥å…·è°ƒç”¨", {
            "tool": tool_name,
            "task_id": meta["task_id"],
            "current_step": current_step
        })

        # å·¥å…·åˆ†å‘å¤„ç†
        step_changed = False

        if tool_name == "Read":
            # æ›´æ–°æ–‡æ¡£é˜…è¯»è®°å½•
            file_path = data.get('tool_input', {}).get('file_path', '')
            if update_docs_read(meta, file_path):
                logger.info(u"æ–‡æ¡£é˜…è¯»è®°å½•å·²æ›´æ–°", {"file": file_path})
                step_changed = check_step_completed(current_step, meta)

        elif tool_name in ["Write", "Edit"]:
            # è®°å½•ä»£ç ä¿®æ”¹
            if update_code_changes(meta, data):
                logger.info(u"ä»£ç ä¿®æ”¹å·²è®°å½•")

        elif tool_name == "Bash":
            # æ£€æµ‹æµ‹è¯•ç»“æœ
            result = data.get('result', {})
            result_str = json.dumps(result, ensure_ascii=False)

            if check_test_failure(result_str):
                meta["metrics"]["failure_count"] += 1

                # è®°å½•é”™è¯¯
                if "failures" not in meta["metrics"]:
                    meta["metrics"]["failures"] = []

                error_record = {
                    "timestamp": datetime.now().isoformat(),
                    "error": result_str[:500],  # é™åˆ¶é•¿åº¦
                    "command": data.get('tool_input', {}).get('command', '')
                }
                meta["metrics"]["failures"].append(error_record)

                # æ›´æ–°step3çš„last_error
                if current_step == "step3_execute":
                    meta["workflow_state"]["steps"]["step3_execute"]["last_error"] = result_str[:200]
                    meta["workflow_state"]["steps"]["step3_execute"]["last_error_time"] = datetime.now().isoformat()

                logger.info(u"Detected test failure", {
                    "failure_count": meta["metrics"]["failure_count"]
                })

                # v20.1: Enhanced expert diagnosis trigger logic
                should_trigger, trigger_reason = should_trigger_expert_diagnosis(meta)

                if should_trigger:
                    inject_expert_review_warning(meta, trigger_reason)
                    meta["metrics"]["expert_review_triggered"] = True

                    # Desktop notification
                    try:
                        from vscode_notify import notify_warning
                        notify_warning("Expert diagnosis recommended", trigger_reason)
                    except:
                        pass

                    step_changed = True

        # æ›´æ–°æ—¶é—´æˆ³
        meta["updated_at"] = datetime.now().isoformat()

        # æ£€æŸ¥æ­¥éª¤æ˜¯å¦åˆšåˆšå®Œæˆ
        if step_changed or check_step_completed(current_step, meta):
            if meta["workflow_state"]["steps"][current_step]["status"] != "completed":
                # æ ‡è®°å½“å‰æ­¥éª¤å®Œæˆ
                meta["workflow_state"]["steps"][current_step]["status"] = "completed"
                meta["workflow_state"]["steps"][current_step]["completed_at"] = datetime.now().isoformat()

                # è·å–ä¸‹ä¸€æ­¥
                next_step = get_next_step(current_step)

                if next_step and current_step != last_injection:
                    # æ›´æ–°çŠ¶æ€æœº
                    meta["workflow_state"]["current_step"] = next_step
                    meta["workflow_state"]["steps"][next_step]["status"] = "in_progress"
                    meta["workflow_state"]["last_injection_step"] = next_step

                    # ä¿å­˜çŠ¶æ€æœº
                    save_json(meta_path, meta)
                    save_json(active_flag_path, {
                        **active_flag,
                        "current_step": next_step,
                        "updated_at": datetime.now().isoformat()
                    })

                    # v20.1: Desktop notification - Step completed
                    next_step_desc = meta["workflow_state"]["steps"][next_step].get("description", next_step)
                    notify_info(
                        "Step completed",
                        "Current: {} â†’ Next: {}".format(current_step, next_step_desc)
                    )

                    # Inject next step prompt
                    inject_next_step_prompt(next_step, meta, cwd)

                    logger.info(u"Step completed", {
                        "from": current_step,
                        "to": next_step
                    })
                    logger.finish(success=True, message=u"æ­¥éª¤{}å®Œæˆ,è¿›å…¥{}".format(current_step, next_step))
                    sys.exit(0)

        # === v20.2 æ–°å¢ï¼šå¾ªç¯æ£€æµ‹ä¸ä¸“å®¶è§¦å‘ ===
        expert_check = check_expert_trigger(meta, cwd)

        if expert_check["should_trigger"] and not meta["metrics"].get("expert_review_triggered", False):
            # è§¦å‘ä¸“å®¶å®¡æŸ¥
            expert_prompt = launch_meta_expert(expert_check, meta, cwd, logger)

            if expert_prompt:
                # æ³¨å…¥ä¸“å®¶åˆ†ææç¤º
                output = {
                    "continue": True,
                    "hookSpecificOutput": {
                        "hookEventName": "PostToolUse",
                        "additionalContext": expert_prompt
                    }
                }
                print(json.dumps(output, ensure_ascii=False))

                # æ¡Œé¢é€šçŸ¥
                try:
                    from vscode_notify import notify_warning
                    notify_warning(
                        u"ä¸“å®¶å®¡æŸ¥å·²è§¦å‘",
                        u"å¾ªç¯ç±»å‹: {} | ç½®ä¿¡åº¦: {:.0%}".format(
                            expert_check["loop_type"],
                            expert_check["confidence"]
                        )
                    )
                except:
                    pass

                logger.finish(success=True, message=u"ä¸“å®¶å®¡æŸ¥å·²è§¦å‘")
                sys.exit(0)

        # ä¿å­˜çŠ¶æ€æœº(å³ä½¿æ²¡æœ‰æ­¥éª¤è·ƒè¿,ä¹Ÿè¦ä¿å­˜æ›´æ–°)
        save_json(meta_path, meta)

        # å½“å‰æ­¥éª¤æœªå®Œæˆ,æ”¾è¡Œ
        logger.decision("continue", u"æ­¥éª¤{}è¿›è¡Œä¸­".format(current_step))
        output = {"continue": True}
        print(json.dumps(output, ensure_ascii=False))
        logger.finish(success=True, message=u"æ”¾è¡Œ")
        sys.exit(0)

    except Exception as e:
        logger.error(u"Hookæ‰§è¡Œå¤±è´¥", e)
        import traceback
        traceback.print_exc(file=sys.stderr)
        output = {"continue": True}
        print(json.dumps(output, ensure_ascii=False))
        logger.finish(success=False, message=u"æ‰§è¡Œå¼‚å¸¸")
        sys.exit(0)

if __name__ == "__main__":
    main()
